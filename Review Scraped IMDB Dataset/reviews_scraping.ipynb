{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['2008', '2003', '2016', '2010', '2001', '2021', '2002', '1999', '1980', '1977', '1962', '1954', '2018', '2000', '1994', '1991', '2017', '2016', '2018', '2019', '2018', '2012', '2003', '1997', '1981', '1986', '1983', '2018', '2018', '2017', '2013', '2012', '2012', '2011', '2005', '2005', '2000', '1998', '1994', '1989', '1988', '1985', '1975', '1961', '1924', '2014', '2017', '2014', 'I) (', '2019']\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from requests import get \n",
    "from bs4 import BeautifulSoup \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from time import sleep\n",
    "from random import randint\n",
    "import lxml\n",
    "from selenium import webdriver\n",
    "import math\n",
    "\n",
    "driver = webdriver.Chrome(executable_path='C:/Users/User/Downloads/chromedriver.exe')\n",
    "\n",
    "def getSoup(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    return soup\n",
    "\n",
    "reviews = []\n",
    "ratings = []\n",
    "titles = []\n",
    "subjects = []\n",
    "total_reviews = []\n",
    "\n",
    "url = '''https://www.imdb.com/search/title/?title_type=feature&num_votes=25000,&genres=action&sort=user_rating,desc&view=simple'''\n",
    "\n",
    "#-----searching for every movie link started\n",
    "movies_soup = getSoup(url)\n",
    "\n",
    "# find all a-tags with class:None\n",
    "movie_tags = movies_soup.find_all('a', attrs={'class': None})\n",
    "\n",
    "# filter the a-tags to get just the titles\n",
    "movie_tags = [tag.attrs['href'] for tag in movie_tags \n",
    "              if tag.attrs['href'].startswith('/title') & tag.attrs['href'].endswith('/')]\n",
    "\n",
    "# remove duplicate links\n",
    "movie_tags = list(dict.fromkeys(movie_tags))\n",
    "\n",
    "base_url = \"https://www.imdb.com\"\n",
    "movie_links = [base_url + tag + 'reviews' for tag in movie_tags]\n",
    "\n",
    "#-----movie links obtained\n",
    "for each in movie_links:\n",
    "   page = requests.get(each)\n",
    "   driver.get(each)\n",
    "   \n",
    "   page_soup = BeautifulSoup(page.text, 'html.parser')\n",
    "   \n",
    "   movies = page_soup.findAll('div',{'class':'lister-item-content'})\n",
    "   movies2 = page_soup.findAll('div',{'class':'subpage_title_block__right-column'})\n",
    "   movies3 = page_soup.findAll('div',{'class':'lister'})\n",
    "   \n",
    "   #to get total reviews for every movie page\n",
    "   for m3 in movies3:\n",
    "        total_reviews.append(int(m3.find('span',{\"class\":\"\"}).text.split(\" \")[0].replace(\",\",\"\")))\n",
    "    \n",
    "    sleep(randint(2,10))\n",
    "\n",
    "    for m2 in movies2:\n",
    "         titles.append(m2.h3.a.text)\n",
    "\n",
    "    for m1 in movies:\n",
    "         reviews.append(str(m1.find('div',{\"class\":\"text show-more__control\"}).text))\n",
    "         ratings.append(m1.find('span',{\"class\":\"\"}).text)\n",
    "         subjects.append(m1.a.text)\n",
    "\n",
    "data = list(zip(reviews,subjects, ratings,titles))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"reviews\",\"subjects\",\"ratings\",\"titles\"])\n",
    "\n",
    "df.to_csv(r'C:\\Users\\User\\Downloads\\try.csv',index=False, header=True)"
   ]
  }
 ]
}